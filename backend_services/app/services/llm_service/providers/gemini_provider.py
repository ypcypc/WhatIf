"""
Google Gemini Provider Implementation

Provides integration with Google Gemini models (Gemini 2.5 Pro, etc.)
"""

import os
import logging
import json
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime

from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.output_parsers import JsonOutputParser

from .base import BaseLLMProvider, LLMProviderConfig, LLMProvider
from ..models import TurnEvent
from ..llm_settings import llm_settings
from backend_services.app.core.config import settings

logger = logging.getLogger(__name__)


class GeminiProvider(BaseLLMProvider):
    """Google Gemini LLM provider implementation."""
    
    def _validate_config(self) -> None:
        """Validate Gemini-specific configuration."""
        if not self.config.api_key:
            # Try to get from settings or environment
            self.config.api_key = settings.google_api_key or os.getenv("GOOGLE_API_KEY")
        
        if not self.config.api_key:
            raise ValueError("Google API key not found. Please set GOOGLE_API_KEY.")
        
        # Validate model name
        valid_models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-1.5-pro", "gemini-1.5-flash"]
        if self.config.model_name not in valid_models:
            logger.warning(f"Unknown Gemini model: {self.config.model_name}")
    
    def _initialize(self) -> None:
        """Initialize Gemini model."""
        self._create_model()
        logger.info(f"Initialized Gemini provider with model: {self.config.model_name}")
    
    def _create_model(self):
        """Create or recreate the Gemini model with current settings."""
        # é…ç½®å®‰å…¨è®¾ç½® - æ”¾å®½é™åˆ¶ä»¥é¿å…ç©ºå“åº”
        safety_settings = {
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        }
        
        logger.info("Creating Gemini model with relaxed safety settings")
        logger.info(f"Safety settings: {safety_settings}")
        
        # Gemini 2.5 Flash æ”¯æŒæœ€å¤š 65536 ä¸ªè¾“å‡ºä»¤ç‰Œ
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®çš„å€¼ï¼Œå®ç°å•ä¸€é…ç½®æºç®¡ç†
        max_output_tokens = self.config.max_tokens or 65536
        
        logger.info(f"Creating Gemini model with max_output_tokens: {max_output_tokens}")
        
        # é…ç½®thinking_budgetå‚æ•°ï¼ˆå¦‚æœè®¾ç½®çš„è¯ï¼‰
        thinking_budget = self.config.thinking_budget
        logger.info(f"Using thinking_budget: {thinking_budget} tokens")
        
        self.model = ChatGoogleGenerativeAI(
            model=self.config.model_name,
            temperature=self.config.temperature,
            google_api_key=self.config.api_key,
            max_output_tokens=max_output_tokens,
            top_p=self.config.top_p,
            top_k=self.config.top_k,
            thinking_budget=thinking_budget,  # æ·»åŠ thinking_budgetå‚æ•°
            convert_system_message_to_human=True,  # Gemini doesn't have system messages
            verbose=True,  # å¯ç”¨è¯¦ç»†æ¨¡å¼
            safety_settings=safety_settings,  # æ·»åŠ å®‰å…¨è®¾ç½®
        )
    
    def update_temperature(self, temperature: float) -> None:
        """Update temperature and recreate model."""
        super().update_temperature(temperature)
        self._create_model()
    
    async def generate_structured_script(
        self,
        prompt: str,
        context: str,
        current_state: Dict[str, Any],
        temperature: float = 0.8,
        max_tokens: Optional[int] = None,
        anchor_info: Optional[Dict[str, Any]] = None,
        session_id: str = None,
        user_event: Optional[TurnEvent] = None,
        assistant_event: Optional[TurnEvent] = None,
        memory_context: str = ""
    ) -> Dict[str, Any]:
        """Generate structured story script using Gemini."""
        try:
            # Update temperature if different
            if temperature != self.config.temperature:
                self.update_temperature(temperature)
            
            # Get system prompt and user message from settings
            system_prompt = llm_settings.get_system_prompt(
                current_state.get('deviation', 0),
                current_state,
                len(context),
                session_id
            )
            
            # Get target counts for content generation
            target_counts = llm_settings.get_required_counts(
                current_state.get('deviation', 0),
                len(context)
            )
            
            # Get generation config
            config = llm_settings.get_generation_config(current_state.get('deviation', 0))
            
            # Build user message
            user_message = llm_settings.get_user_message(
                context=context,
                memory_context=memory_context,
                prompt=prompt,
                anchor_info=anchor_info,
                current_state=current_state,
                target_counts=target_counts,
                config=config,
                session_id=session_id
            )
            
            # Format instructions for JSON output
            format_instructions = self._get_json_format_instructions(target_counts)
            
            # Create messages for Gemini
            # Combine system and user messages since Gemini doesn't support system messages
            # ç®€åŒ–æ¶ˆæ¯æ ¼å¼ï¼Œé¿å…è¿‡é•¿çš„ç³»ç»ŸæŒ‡ä»¤
            
            logger.info("Building combined message for Gemini...")
            logger.info(f"System prompt length: {len(system_prompt)}")
            logger.info(f"User message length: {len(user_message)}")
            logger.info(f"Format instructions length: {len(format_instructions)}")
            
            # æ„å»ºæ›´ç®€æ´çš„æ¶ˆæ¯
            combined_message = f"""è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆæ¸¸æˆè„šæœ¬ï¼š

{user_message}

{format_instructions}"""
            
            logger.info(f"Final combined message length: {len(combined_message)}")
            logger.info(f"Combined message preview (first 1000 chars):\n{combined_message[:1000]}...")
            
            messages = [HumanMessage(content=combined_message)]
            logger.info(f"Message object created: {type(messages[0])}")
            logger.info(f"Message content length: {len(messages[0].content)}")
            
            # Log the generation request
            logger.info(f"Generating script for session {session_id} with {self.config.model_name}")
            logger.debug(f"Temperature: {temperature}, Deviation: {current_state.get('deviation', 0)}")
            
            # Log the request details before generation
            logger.info(f"Sending request to Gemini API:")
            logger.info(f"Model: {self.config.model_name}")
            logger.info(f"Temperature: {temperature}")
            logger.info(f"Max tokens: {self.config.max_tokens}")
            logger.info(f"Message length: {len(combined_message)} characters")
            logger.info(f"First 500 chars of message: {combined_message[:500]}...")
            
            # éªŒè¯å½“å‰æ¨¡å‹çš„å®‰å…¨è®¾ç½®
            if hasattr(self.model, 'safety_settings'):
                logger.info(f"Active safety settings: {self.model.safety_settings}")
            else:
                logger.warning("No safety_settings attribute found on model!")
                
            # è®°å½•å®é™…çš„æ¨¡å‹é…ç½®
            logger.info(f"Model configuration:")
            for attr in ['model', 'temperature', 'max_output_tokens', 'top_p', 'top_k']:
                if hasattr(self.model, attr):
                    logger.info(f"  {attr}: {getattr(self.model, attr)}")
            
            # æ£€æŸ¥æ¶ˆæ¯ä¸­å¯èƒ½è§¦å‘è¿‡æ»¤çš„å…³é”®è¯
            potentially_sensitive_keywords = ['é¾™', 'é‚ªæ¶', 'åˆ©çˆª', 'å¦–æ°”', 'æš´é£é¾™', 'å°å°', 'å‹‡è€…']
            found_keywords = [kw for kw in potentially_sensitive_keywords if kw in combined_message]
            if found_keywords:
                logger.info(f"Potentially sensitive keywords found: {found_keywords}")
            else:
                logger.info("No obviously sensitive keywords detected")
            
            # Generate response with retry mechanism
            start_time = datetime.now()
            logger.info("Calling Gemini API...")
            
            max_retries = 3
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    logger.info(f"Attempt {attempt + 1}/{max_retries}")
                    response = await self.model.ainvoke(messages)
                    
                    # è¯¦ç»†åˆ†æå“åº”å¯¹è±¡
                    logger.info("=" * 80)
                    logger.info(f"ATTEMPT {attempt + 1} - DETAILED RESPONSE ANALYSIS:")
                    logger.info("=" * 80)
                    
                    # æ£€æŸ¥å“åº”åŸºæœ¬ä¿¡æ¯
                    logger.info(f"Response object type: {type(response)}")
                    logger.info(f"Response content length: {len(response.content) if response.content else 0}")
                    logger.info(f"Response content: '{response.content}'")
                    
                    # æ£€æŸ¥å®‰å…¨ç›¸å…³ä¿¡æ¯
                    if hasattr(response, 'response_metadata') and response.response_metadata:
                        metadata = response.response_metadata
                        logger.info(f"Response metadata: {metadata}")
                        
                        # é‡ç‚¹æ£€æŸ¥å®‰å…¨è¯„çº§
                        if 'safety_ratings' in metadata:
                            logger.info(f"Safety ratings: {metadata['safety_ratings']}")
                        
                        if 'prompt_feedback' in metadata:
                            prompt_feedback = metadata['prompt_feedback']
                            logger.info(f"Prompt feedback: {prompt_feedback}")
                            
                            if 'block_reason' in prompt_feedback:
                                block_reason = prompt_feedback['block_reason']
                                logger.info(f"Block reason: {block_reason}")
                                if block_reason != 0:
                                    logger.error(f"REQUEST BLOCKED! Block reason: {block_reason}")
                        
                        if 'finish_reason' in metadata:
                            finish_reason = metadata['finish_reason']
                            logger.info(f"Finish reason: {finish_reason}")
                            if finish_reason != 'STOP':
                                logger.warning(f"Unusual finish reason: {finish_reason}")
                    
                    # æ£€æŸ¥usageä¿¡æ¯
                    if hasattr(response, 'usage_metadata') and response.usage_metadata:
                        logger.info(f"Usage metadata: {response.usage_metadata}")
                    
                    logger.info("=" * 80)
                    
                    # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
                    if not response.content:
                        logger.warning(f"Attempt {attempt + 1}: Empty response received")
                        
                        # åˆ†æç©ºå“åº”çš„å¯èƒ½åŸå› 
                        if hasattr(response, 'response_metadata') and response.response_metadata:
                            metadata = response.response_metadata
                            finish_reason = metadata.get('finish_reason', '')
                            
                            if metadata.get('prompt_feedback', {}).get('block_reason', 0) != 0:
                                logger.error("Empty response due to content blocking!")
                            elif finish_reason == 'SAFETY':
                                logger.error("Empty response due to safety filtering!")
                            elif finish_reason == 'MAX_TOKENS':
                                logger.error("Empty response due to MAX_TOKENS - output was truncated!")
                                logger.error("This usually means the requested output is too long for the model")
                                # è®°å½•å½“å‰çš„ max_output_tokens è®¾ç½®
                                if hasattr(self.model, 'max_output_tokens'):
                                    logger.error(f"Current max_output_tokens: {self.model.max_output_tokens}")
                            else:
                                logger.error(f"Empty response for unknown reason! finish_reason: {finish_reason}")
                        
                        if attempt < max_retries - 1:
                            logger.info("Retrying due to empty response...")
                            continue
                        else:
                            logger.error("All attempts resulted in empty responses")
                    else:
                        logger.info(f"Attempt {attempt + 1}: Successful response received")
                        break
                        
                except Exception as e:
                    last_exception = e
                    logger.error(f"Attempt {attempt + 1} failed with exception: {type(e).__name__}: {e}")
                    
                    # å°è¯•ä»å¼‚å¸¸ä¸­æå–æ›´å¤šä¿¡æ¯
                    if hasattr(e, 'response') and e.response:
                        logger.error(f"Exception response object: {e.response}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹å®šçš„Google APIé”™è¯¯
                    if 'InternalServerError' in str(type(e)):
                        logger.error("This is a Google API internal server error (500)")
                        logger.error("This indicates a server-side issue, not a client problem")
                    
                    if attempt < max_retries - 1:
                        wait_time = (2 ** attempt)  # æŒ‡æ•°é€€é¿: 1s, 2s, 4s
                        logger.info(f"Waiting {wait_time} seconds before retry...")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error("All retry attempts failed")
                        raise e
            
            generation_time = (datetime.now() - start_time).total_seconds()
            
            logger.info(f"Gemini API call completed in {generation_time:.2f} seconds")
            
            # Debug response object structure
            logger.info("=" * 80)
            logger.info("GEMINI RESPONSE OBJECT ANALYSIS:")
            logger.info("=" * 80)
            logger.info(f"Response type: {type(response)}")
            logger.info(f"Response attributes: {dir(response)}")
            
            # Check all possible response attributes
            if hasattr(response, 'content'):
                logger.info(f"Response content length: {len(response.content) if response.content else 0}")
                logger.info(f"Response content type: {type(response.content)}")
                logger.info(f"Response content: '{response.content}'")
            
            if hasattr(response, 'response_metadata'):
                logger.info(f"Response metadata: {response.response_metadata}")
            
            if hasattr(response, 'usage_metadata'):
                logger.info(f"Usage metadata: {response.usage_metadata}")
            
            # Check for any additional response information
            logger.info(f"Full response object: {response}")
            logger.info("=" * 80)
            
            # Extract and parse JSON from response
            response_text = response.content if response.content else ""
            logger.info(f"Extracted response_text: '{response_text}'")
            
            result = self._parse_json_response(response_text, prompt, current_state)
            
            # Add metadata
            result['metadata'] = result.get('metadata', {})
            result['metadata'].update({
                'model': self.config.model_name,
                'temperature': temperature,
                'generation_time': generation_time,
                'session_id': session_id,
                'provider': 'gemini'
            })
            
            logger.info(f"Successfully generated script with {len(result.get('script_units', []))} units")
            
            return result
            
        except Exception as e:
            logger.error(f"Gemini generation failed: {e}")
            logger.error(f"Exception type: {type(e).__name__}")
            logger.error(f"Exception details: {str(e)}")
            
            # If we have a response_text variable, print it for debugging
            if 'response_text' in locals():
                logger.error("=" * 80)
                logger.error("GEMINI RESPONSE AT EXCEPTION TIME:")
                logger.error("=" * 80)
                logger.error(f"Response length: {len(response_text)} characters")
                logger.error(f"Full response text:\n{response_text}")
                logger.error("=" * 80)
            
            # Print full stack trace for debugging
            import traceback
            logger.error(f"Full traceback:\n{traceback.format_exc()}")
            
            return self._create_fallback_response(prompt, current_state)
    
    def _get_json_format_instructions(self, target_counts: Dict[str, int]) -> str:
        """Get JSON format instructions for Gemini."""
        return f"""
è¯·ç”Ÿæˆä¸€ä¸ªä¸¥æ ¼ç¬¦åˆä»¥ä¸‹JSONæ ¼å¼çš„å“åº”ï¼š
{{
    "script_units": [
        {{
            "type": "narration|dialogue|interaction",
            "content": "å•å…ƒå†…å®¹",
            "speaker": "è§’è‰²IDï¼ˆå¯¹è¯æ—¶å¿…é¡»ä½¿ç”¨IDï¼Œå¦‚char_001ï¼‰",
            "choice_id": "é€‰æ‹©IDï¼ˆäº¤äº’æ—¶éœ€è¦ï¼‰",
            "default_reply": "é»˜è®¤å›å¤ï¼ˆäº¤äº’æ—¶éœ€è¦ï¼‰",
            "metadata": {{}}
        }}
    ],
    "required_counts": {{
        "narration": {target_counts.get('narration', 5)},
        "dialogue": {target_counts.get('dialogue', 5)},
        "interaction": 1
    }},
    "deviation_delta": -20åˆ°20çš„æ•°å­—,
    "new_deviation": 0åˆ°100çš„æ•°å­—,
    "deviation_reasoning": "åç¦»åº¦è¯„ä¼°ç†ç”±",
    "affinity_changes": {{}},
    "flags_updates": {{}},
    "variables_updates": {{}},
    "metadata": {{}}
}}

é‡è¦ï¼š
1. å¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
2. æ‰€æœ‰å­—ç¬¦ä¸²éƒ½è¦æ­£ç¡®è½¬ä¹‰
3. æ•°å­—ä¸è¦åŠ å¼•å·
4. æœ€åä¸€ä¸ªscript_unitå¿…é¡»æ˜¯interactionç±»å‹
5. åªè¿”å›JSONï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—è¯´æ˜
"""
    
    def _parse_json_response(self, response_text: str, prompt: str, current_state: Dict[str, Any]) -> Dict[str, Any]:
        """Parse JSON from Gemini response."""
        try:
            logger.info("=" * 80)
            logger.info("JSON PARSING ANALYSIS:")
            logger.info("=" * 80)
            logger.info(f"Input response_text type: {type(response_text)}")
            logger.info(f"Input response_text length: {len(response_text) if response_text else 0}")
            logger.info(f"Response_text is None: {response_text is None}")
            logger.info(f"Response_text is empty string: {response_text == ''}")
            logger.info(f"Response_text repr: {repr(response_text)}")
            
            if not response_text:
                logger.error("Response text is None or empty - this indicates Gemini returned no content")
                raise ValueError("Empty response from Gemini API")
            
            # Try to find JSON in the response
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            
            logger.info(f"JSON search results:")
            logger.info(f"  First '{{' found at position: {json_start}")
            logger.info(f"  Last '}}' found at position: {json_end - 1 if json_end > 0 else -1}")
            
            if json_start != -1 and json_end > json_start:
                json_str = response_text[json_start:json_end]
                logger.info(f"Extracted JSON string length: {len(json_str)}")
                logger.info(f"First 200 chars of JSON: {json_str[:200]}...")
                logger.info(f"Last 200 chars of JSON: ...{json_str[-200:]}")
                
                parsed_json = json.loads(json_str)
                logger.info("JSON parsing successful!")
                logger.info(f"Parsed JSON keys: {list(parsed_json.keys()) if isinstance(parsed_json, dict) else 'Not a dict'}")
                return parsed_json
            else:
                logger.error("No valid JSON boundaries found in response")
                raise ValueError("No JSON found in response")
                
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Failed to parse Gemini response as JSON: {e}")
            logger.error("=" * 80)
            logger.error("COMPLETE GEMINI RESPONSE FOR DEBUGGING:")
            logger.error("=" * 80)
            logger.error(f"Response length: {len(response_text)} characters")
            logger.error(f"Full response text:\n{response_text}")
            logger.error("=" * 80)
            logger.error("JSON EXTRACTION ATTEMPT:")
            logger.error(f"JSON start position: {response_text.find('{')}")
            logger.error(f"JSON end position: {response_text.rfind('}')}")
            if response_text.find('{') != -1 and response_text.rfind('}') != -1:
                json_attempt = response_text[response_text.find('{'):response_text.rfind('}') + 1]
                logger.error(f"Extracted JSON attempt: {json_attempt}")
            logger.error("=" * 80)
            return self._create_fallback_response(prompt, current_state)
    
    async def generate_summary(self, text: str, max_length: int = 500) -> str:
        """Generate a summary using Gemini."""
        try:
            prompt = llm_settings.get_summarization_prompt().format(text=text)
            
            # ä½¿ç”¨ç›¸åŒçš„å®‰å…¨è®¾ç½®
            safety_settings = {
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            }
            
            # Create a low-temperature model for summaries
            summary_model = ChatGoogleGenerativeAI(
                model=self.config.model_name,
                temperature=0.3,
                google_api_key=self.config.api_key,
                max_output_tokens=max_length,
                safety_settings=safety_settings,
                verbose=True
            )
            
            response = await summary_model.ainvoke([
                HumanMessage(content=prompt)
            ])
            
            logger.info(f"Summary response content: '{response.content}'")
            return response.content.strip() if response.content else "[æ€»ç»“å¤±è´¥ - ç©ºå“åº”]"
            
        except Exception as e:
            logger.error(f"Gemini summarization failed: {e}")
            return f"[æ€»ç»“å¤±è´¥] {text[:max_length]}..."
    
    async def debug_content_test(self, test_content: str, test_name: str = "unnamed") -> Dict[str, Any]:
        """
        ä¸“é—¨ç”¨äºè°ƒè¯•çš„å†…å®¹æµ‹è¯•å‡½æ•°
        æµ‹è¯•ä¸åŒç±»å‹çš„å†…å®¹æ˜¯å¦ä¼šè§¦å‘500é”™è¯¯æˆ–å®‰å…¨è¿‡æ»¤
        """
        logger.info(f"=" * 80)
        logger.info(f"DEBUG CONTENT TEST: {test_name}")
        logger.info(f"=" * 80)
        logger.info(f"Test content length: {len(test_content)} characters")
        logger.info(f"Test content: {test_content[:200]}...")
        
        try:
            response = await self.model.ainvoke([
                HumanMessage(content=test_content)
            ])
            
            # è¯¦ç»†åˆ†ææµ‹è¯•å“åº”
            logger.info(f"Test '{test_name}' - Response analysis:")
            logger.info(f"  Content length: {len(response.content) if response.content else 0}")
            logger.info(f"  Content: '{response.content}'")
            
            if hasattr(response, 'response_metadata') and response.response_metadata:
                metadata = response.response_metadata
                logger.info(f"  Metadata: {metadata}")
                
                if 'prompt_feedback' in metadata:
                    prompt_feedback = metadata['prompt_feedback']
                    block_reason = prompt_feedback.get('block_reason', 0)
                    logger.info(f"  Block reason: {block_reason}")
                    if block_reason != 0:
                        logger.error(f"  âŒ CONTENT BLOCKED! Block reason: {block_reason}")
                        return {"success": False, "reason": "content_blocked", "block_reason": block_reason}
                
                if 'finish_reason' in metadata:
                    finish_reason = metadata['finish_reason']
                    logger.info(f"  Finish reason: {finish_reason}")
                    if finish_reason == 'SAFETY':
                        logger.error(f"  âŒ SAFETY FILTERED!")
                        return {"success": False, "reason": "safety_filtered"}
            
            if response.content:
                logger.info(f"  âœ… Test '{test_name}' PASSED")
                return {"success": True, "response_length": len(response.content)}
            else:
                logger.error(f"  âŒ Test '{test_name}' returned empty response")
                return {"success": False, "reason": "empty_response"}
                
        except Exception as e:
            logger.error(f"  âŒ Test '{test_name}' failed with exception: {type(e).__name__}: {e}")
            return {"success": False, "reason": "exception", "error": str(e)}
    
    async def run_progressive_content_tests(self) -> Dict[str, Any]:
        """
        è¿è¡Œæ¸è¿›å¼å†…å®¹æµ‹è¯•ï¼Œæ‰¾åˆ°è§¦å‘é—®é¢˜çš„ä¸´ç•Œç‚¹
        """
        logger.info("ğŸ§ª STARTING PROGRESSIVE CONTENT TESTS")
        
        test_results = {}
        
        # æµ‹è¯•1ï¼šç®€å•è‹±æ–‡
        test_results["simple_english"] = await self.debug_content_test(
            "Hello, please respond with a simple JSON: {\"status\": \"ok\"}",
            "Simple English"
        )
        
        # æµ‹è¯•2ï¼šç®€å•æ—¥æ–‡
        test_results["simple_japanese"] = await self.debug_content_test(
            "ã“ã‚“ã«ã¡ã¯ã€‚ç°¡å˜ãªJSONã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š{\"status\": \"ok\"}",
            "Simple Japanese"
        )
        
        # æµ‹è¯•3ï¼šçŸ­çš„è½¬ä¸–å²è±å§†å†…å®¹
        test_results["short_slime"] = await self.debug_content_test(
            "æˆ‘å˜æˆäº†å²è±å§†ã€‚è¿™ä¸ªä¸–ç•Œå¾ˆç¥å¥‡ã€‚è¯·ç”ŸæˆJSONï¼š{\"story\": \"å¼€å§‹å†’é™©\"}",
            "Short Slime Content"
        )
        
        # æµ‹è¯•4ï¼šåŒ…å«"æ•æ„Ÿ"å…³é”®è¯çš„å†…å®¹
        test_results["with_keywords"] = await self.debug_content_test(
            "é¾™å¾ˆå¼ºå¤§ï¼Œæœ‰ç€é‚ªæ¶çš„å¤–è¡¨å’Œåˆ©çˆªã€‚ä½†å®ƒå…¶å®å¾ˆå–„è‰¯ã€‚è¯·ç”ŸæˆJSONï¼š{\"character\": \"friendly dragon\"}",
            "Content with Sensitive Keywords"
        )
        
        # æµ‹è¯•5ï¼šä¸­ç­‰é•¿åº¦çš„æ¸¸æˆå†…å®¹
        medium_content = """
        è¿™åªé¾™ä¼¼ä¹å¾ˆå–œæ¬¢äººç±»ã€‚å˜´å·´ä¸Šå°å–½å•°ã€åƒåœ¾åœ°å«ï¼Œå´ä¸æ›¾è“„æ„æ€å®³å‰æ¥æŒ‘è¡…çš„å®¶ä¼™ã€‚
        è¿‡å»æ›¾æœ‰ä¸€æ¬¡ï¼Œå› ä¸ºä¸‰ç™¾å¹´å‰å‘ç”Ÿäº†æŸä»¶äº‹ï¼Œæ‰€ä»¥ä»–æŠŠåŸé•‡ç­äº†ã€‚
        ç°åœ¨æˆ‘ä»¬è¦æˆä¸ºæœ‹å‹ã€‚è¯·ç”Ÿæˆæ¸¸æˆè„šæœ¬JSONæ ¼å¼ï¼š
        {"script_units": [{"type": "dialogue", "content": "æˆ‘ä»¬åšæœ‹å‹å§"}]}
        """
        test_results["medium_game_content"] = await self.debug_content_test(
            medium_content.strip(),
            "Medium Game Content"
        )
        
        logger.info("ğŸ§ª PROGRESSIVE CONTENT TESTS COMPLETED")
        logger.info(f"Test results summary: {test_results}")
        
        return test_results

    async def generate_simplified_script(
        self,
        simplified_content: str,
        max_units: int = 3,
        target_length: int = 1000
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆç®€åŒ–ç‰ˆæœ¬çš„è„šæœ¬ï¼Œç”¨äºæµ‹è¯•æ˜¯å¦èƒ½é¿å…500é”™è¯¯
        
        Args:
            simplified_content: ç®€åŒ–çš„è¾“å…¥å†…å®¹
            max_units: æœ€å¤§è„šæœ¬å•å…ƒæ•°
            target_length: ç›®æ ‡é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
        """
        logger.info("ğŸ§ª GENERATING SIMPLIFIED SCRIPT FOR TESTING")
        logger.info(f"Input length: {len(simplified_content)} characters")
        logger.info(f"Max units: {max_units}")
        logger.info(f"Target length: {target_length}")
        
        # æç®€çš„JSONæ ¼å¼æŒ‡ä»¤
        simple_format = f"""
è¯·ç”Ÿæˆä¸€ä¸ªç®€å•çš„JSONæ ¼å¼å“åº”ï¼š
{{
    "script_units": [
        {{"type": "narration", "content": "æ•…äº‹å†…å®¹"}},
        {{"type": "dialogue", "content": "å¯¹è¯å†…å®¹", "speaker": "char_001"}},
        {{"type": "interaction", "content": "äº¤äº’é—®é¢˜", "choice_id": "choice_1", "default_reply": "é»˜è®¤å›å¤"}}
    ],
    "deviation_delta": 0,
    "new_deviation": 0
}}

è¯·åŸºäºä»¥ä¸‹å†…å®¹ç”Ÿæˆ{max_units}ä¸ªè„šæœ¬å•å…ƒï¼ˆæ€»é•¿åº¦çº¦{target_length}å­—ç¬¦ï¼‰ï¼š
{simplified_content[:500]}...
"""
        
        try:
            response = await self.model.ainvoke([
                HumanMessage(content=simple_format)
            ])
            
            logger.info("Simplified generation completed")
            logger.info(f"Response length: {len(response.content) if response.content else 0}")
            
            if response.content:
                # å°è¯•è§£æJSON
                try:
                    import json
                    json_start = response.content.find('{')
                    json_end = response.content.rfind('}') + 1
                    
                    if json_start != -1 and json_end > json_start:
                        json_str = response.content[json_start:json_end]
                        result = json.loads(json_str)
                        logger.info("âœ… Simplified generation successful!")
                        return result
                    else:
                        logger.warning("No JSON found in simplified response")
                        return {"error": "no_json", "raw_response": response.content}
                        
                except json.JSONDecodeError as e:
                    logger.warning(f"JSON parsing failed: {e}")
                    return {"error": "json_parse_failed", "raw_response": response.content}
            else:
                logger.error("âŒ Simplified generation returned empty response")
                return {"error": "empty_response"}
                
        except Exception as e:
            logger.error(f"âŒ Simplified generation failed: {type(e).__name__}: {e}")
            return {"error": "exception", "details": str(e)}

    async def health_check(self) -> Dict[str, Any]:
        """Check Gemini API health status."""
        try:
            logger.info("Performing Gemini API health check...")
            
            # Try a simple generation
            test_message = "Say 'OK' if you're working."
            logger.info(f"Sending test message: {test_message}")
            
            response = await self.model.ainvoke([
                HumanMessage(content=test_message)
            ])
            
            logger.info(f"Health check response: {response}")
            logger.info(f"Health check response content: '{response.content}'")
            logger.info(f"Health check response length: {len(response.content) if response.content else 0}")
            
            return {
                "gemini_available": True,
                "model": self.config.model_name,
                "provider": "gemini",
                "status": "healthy",
                "response": response.content[:50] if response.content else "Empty response",
                "full_response_length": len(response.content) if response.content else 0
            }
        except Exception as e:
            logger.error(f"Gemini health check failed: {e}")
            logger.error(f"Health check exception type: {type(e).__name__}")
            
            # Import traceback for detailed error info
            import traceback
            logger.error(f"Health check full traceback:\n{traceback.format_exc()}")
            
            return {
                "gemini_available": False,
                "model": self.config.model_name,
                "provider": "gemini",
                "status": "unhealthy",
                "error": str(e),
                "error_type": type(e).__name__
            }
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get information about the current model."""
        return {
            "provider": "gemini",
            "model": self.config.model_name,
            "temperature_range": (0.0, 2.0),
            "supports_functions": False,  # Gemini uses JSON mode
            "max_tokens": self.config.max_tokens or 8192,
            "features": {
                "structured_output": True,
                "function_calling": False,
                "json_mode": True,
                "vision": True,
                "multimodal": True
            }
        }