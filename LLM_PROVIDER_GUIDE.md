# ç»Ÿä¸€ LLM æä¾›å•†ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## ğŸ¯ æ¦‚è¿°

WhatIf é¡¹ç›®ç°åœ¨æ”¯æŒç»Ÿä¸€çš„ LLM æä¾›å•†ç³»ç»Ÿï¼Œå¯ä»¥æ— ç¼åˆ‡æ¢ä½¿ç”¨ä¸åŒçš„ AI æ¨¡å‹ï¼š
- **OpenAI**: GPT-4, GPT-4o, GPT-4o-mini, o4-mini
- **Google Gemini**: Gemini 2.5 Pro, Gemini 2.5 Flash
- **å¯æ‰©å±•æ¶æ„**: è½»æ¾æ·»åŠ æ›´å¤šæä¾›å•†

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd backend_services
poetry install
```

è¿™ä¼šè‡ªåŠ¨å®‰è£…åŒ…å« Gemini æ”¯æŒçš„æ‰€æœ‰ä¾èµ–ï¼š
- `langchain-google-genai = "^2.1.8"`
- `google-genai = "^1.0.0"`

### 2. é…ç½® API å¯†é’¥

**é€‰é¡¹ A: ä½¿ç”¨ç¯å¢ƒå˜é‡**
```bash
# å®‰å…¨æ¨èï¼šåˆ›å»º api_keys.env æ–‡ä»¶
cp api_keys.env.example api_keys.env

# ç¼–è¾‘ api_keys.env æ·»åŠ æ‚¨çš„å¯†é’¥
export GOOGLE_API_KEY="æ‚¨çš„-Google-API-å¯†é’¥"
export OPENAI_API_KEY="æ‚¨çš„-OpenAI-API-å¯†é’¥"

# åŠ è½½ç¯å¢ƒå˜é‡
source api_keys.env
```

**é€‰é¡¹ B: ç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡**
```bash
export GOOGLE_API_KEY="æ‚¨çš„-Google-API-å¯†é’¥"
export LLM_PROVIDER="gemini"
export LLM_MODEL="gemini-2.5-pro"
```

### 3. å¯åŠ¨åº”ç”¨

```bash
# å¯åŠ¨åç«¯
uvicorn app.main:app --reload --port 8000

# å¯åŠ¨å‰ç«¯
cd ..
npm run dev
```

## ğŸ”§ é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|-------|-------|------|
| `LLM_PROVIDER` | `"openai"` | ä½¿ç”¨çš„ LLM æä¾›å•† (`openai`, `gemini`) |
| `LLM_MODEL` | `"gpt-4o-mini"` | å…·ä½“çš„æ¨¡å‹åç§° |
| `GOOGLE_API_KEY` | - | Google Gemini API å¯†é’¥ |
| `OPENAI_API_KEY` | - | OpenAI API å¯†é’¥ |

### æ”¯æŒçš„æ¨¡å‹

#### OpenAI æ¨¡å‹
- `gpt-4o-mini` (æ¨èï¼Œæ€§ä»·æ¯”é«˜)
- `gpt-4o` (æœ€æ–°åŠŸèƒ½)
- `gpt-4-turbo` (å¹³è¡¡æ€§èƒ½)
- `o4-mini` (æ¨ç†ä¸“ç”¨)

#### Gemini æ¨¡å‹
- `gemini-2.5-pro` (æ¨èï¼Œæœ€æ–°ç‰ˆæœ¬)
- `gemini-2.5-flash` (é€Ÿåº¦ä¼˜åŒ–)
- `gemini-1.5-pro` (ç¨³å®šç‰ˆæœ¬)
- `gemini-1.5-flash` (å¿«é€Ÿç‰ˆæœ¬)

## ğŸ”„ è¿è¡Œæ—¶åˆ‡æ¢

### é€šè¿‡ API åˆ‡æ¢ (å¼€å‘ä¸­)
```python
# åœ¨è¿è¡Œæ—¶åˆ‡æ¢åˆ° Gemini
POST /api/v1/llm/switch-provider
{
    "provider": "gemini",
    "model": "gemini-2.5-pro"
}
```

### é€šè¿‡ä»£ç åˆ‡æ¢
```python
from app.services.llm_service.providers import switch_provider

# åˆ‡æ¢åˆ° Gemini 2.5 Pro
provider = switch_provider("gemini", "gemini-2.5-pro")

# åˆ‡æ¢å› OpenAI
provider = switch_provider("openai", "gpt-4o-mini")
```

## ğŸ§ª æµ‹è¯•éªŒè¯

### è¿è¡Œæµ‹è¯•è„šæœ¬
```bash
cd backend_services
python test_unified_llm.py
```

è¿™ä¼šæµ‹è¯•ï¼š
- âœ… æä¾›å•†å·¥å‚åŠŸèƒ½
- âœ… å¤šä¸ªæä¾›å•†åˆ›å»º
- âœ… ç»Ÿä¸€ä»“åº“æ“ä½œ
- âœ… æ–‡æœ¬ç”Ÿæˆæµ‹è¯•
- âœ… æ‘˜è¦ç”Ÿæˆæµ‹è¯•

### é¢„æœŸè¾“å‡º
```
ğŸ§ª Unified LLM Provider System Test
============================================================
OpenAI API Key: âœ…
Gemini API Key: âœ…

ğŸ­ Testing LLM Provider Factory
==================================================
Available providers:
  - openai: gpt-4o-mini (Available: True)
  - gemini: gemini-2.5-pro (Available: True)

ğŸ”§ Testing Provider Creation
==================================================
âœ… OpenAI provider created: gpt-4o-mini
   Health: healthy
âœ… Gemini provider created: gemini-2.5-pro
   Health: healthy

ğŸ—ƒï¸ Testing Unified Repository
==================================================
âœ… Repository created with provider: gemini
   Current provider: gemini
   Current model: gemini-2.5-pro
   Health status: healthy

âœï¸ Testing Text Generation
==================================================
Context: ä¸»è§’èµ°è¿›äº†ä¸€ä¸ªç¥ç§˜çš„æˆ¿é—´ï¼Œé‡Œé¢å…‰çº¿æ˜æš—ã€‚
Player choice: ä»”ç»†è§‚å¯Ÿæˆ¿é—´
Using provider: gemini

ğŸ“œ Generated Script:
  1. [narration] ä¸»è§’å°å¿ƒç¿¼ç¿¼åœ°æ­¥å…¥æˆ¿é—´...
  2. [dialogue] ä¸»è§’: "è¿™é‡Œæœ‰ä»€ä¹ˆ..."
  3. [interaction] æ¥ä¸‹æ¥ä½ è¦åšä»€ä¹ˆï¼Ÿ
```

## ğŸ® æ¸¸æˆä¸­çš„ä½¿ç”¨æ•ˆæœ

### Gemini 2.5 Pro ç‰¹è‰²
1. **å¤šæ¨¡æ€èƒ½åŠ›**: æ”¯æŒæ–‡æœ¬ã€å›¾åƒè¾“å…¥
2. **æ›´å¤§ä¸Šä¸‹æ–‡**: æ”¯æŒæ›´é•¿çš„å¯¹è¯å†å²
3. **åˆ›é€ æ€§å¼º**: åœ¨é«˜åç¦»åº¦æ—¶è¡¨ç°ä¼˜å¼‚
4. **æˆæœ¬æ•ˆç›Š**: ç›¸æ¯” GPT-4 æ›´å…·æ€§ä»·æ¯”

### ä¸åŠ¨æ€ Temperature çš„æ•´åˆ
```python
# è‡ªåŠ¨æ ¹æ®åç¦»åº¦è°ƒæ•´åˆ›é€ æ€§
deviation = 0.15  # 15% åç¦»åº¦
temperature = calculate_dynamic_temperature(deviation)
# Gemini ä½¿ç”¨: temperature = 0.48 (é€‚åº¦åˆ›é€ æ€§)

result = await gemini_provider.generate_structured_script(
    prompt="é€‰æ‹©ç›¸ä¿¡å¥¹",
    context="åŸæ–‡å†…å®¹...",
    temperature=temperature  # è‡ªåŠ¨è°ƒèŠ‚
)
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ç‰¹æ€§ | OpenAI GPT-4o-mini | Gemini 2.5 Pro | å¤‡æ³¨ |
|------|-------------------|----------------|------|
| å“åº”é€Ÿåº¦ | â­â­â­â­ | â­â­â­ | OpenAI ç•¥å¿« |
| åˆ›é€ æ€§ | â­â­â­ | â­â­â­â­ | Gemini æ›´æœ‰åˆ›æ„ |
| ä¸€è‡´æ€§ | â­â­â­â­ | â­â­â­ | OpenAI æ›´ç¨³å®š|
| æˆæœ¬ | $0.15/1K tokens | $1.25/1K tokens | OpenAI æ›´ä¾¿å®œ |
| ä¸Šä¸‹æ–‡é•¿åº¦ | 128K tokens | 2M tokens | Gemini æ›´é•¿ |
| å¤šæ¨¡æ€ | éƒ¨åˆ†æ”¯æŒ | å…¨é¢æ”¯æŒ | Gemini æ›´å¼º |

## ğŸ”’ å®‰å…¨æ³¨æ„äº‹é¡¹

### API å¯†é’¥ç®¡ç†
1. **ä¸è¦æäº¤å¯†é’¥**: ç¡®ä¿ `.env` æ–‡ä»¶åœ¨ `.gitignore` ä¸­
2. **ä½¿ç”¨ç¯å¢ƒå˜é‡**: é¿å…ç¡¬ç¼–ç  API å¯†é’¥
3. **å®šæœŸè½®æ¢**: å®šæœŸæ›´æ–° API å¯†é’¥
4. **æƒé™æœ€å°åŒ–**: åªç»™äºˆå¿…è¦çš„ API æƒé™

### ç¤ºä¾‹ `.gitignore`
```
# API Keys - æ°¸è¿œä¸è¦æäº¤è¿™äº›æ–‡ä»¶
api_keys.env
.env
*.key
*_key.txt
```

## ğŸ› ï¸ å¼€å‘è€…æŒ‡å—

### æ·»åŠ æ–°çš„ LLM æä¾›å•†

1. **åˆ›å»ºæä¾›å•†ç±»**:
```python
# providers/new_provider.py
class NewProvider(BaseLLMProvider):
    def _validate_config(self):
        # éªŒè¯é…ç½®
        pass
    
    def _initialize(self):
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        pass
    
    async def generate_structured_script(self, ...):
        # å®ç°ç”Ÿæˆé€»è¾‘
        pass
```

2. **æ³¨å†Œåˆ°å·¥å‚**:
```python
# providers/provider_factory.py
_providers = {
    LLMProvider.OPENAI: OpenAIProvider,
    LLMProvider.GEMINI: GeminiProvider,
    LLMProvider.NEW: NewProvider,  # æ·»åŠ è¿™è¡Œ
}
```

3. **æ›´æ–°æšä¸¾**:
```python
# providers/base.py
class LLMProvider(str, Enum):
    OPENAI = "openai"
    GEMINI = "gemini"
    NEW = "new"  # æ·»åŠ è¿™è¡Œ
```

### è‡ªå®šä¹‰é…ç½®
```python
# åˆ›å»ºè‡ªå®šä¹‰é…ç½®çš„æä¾›å•†
from app.services.llm_service.providers import LLMProviderFactory

provider = LLMProviderFactory.create_provider(
    provider="gemini",
    model="gemini-2.5-pro",
    temperature=0.9,
    max_tokens=4096,
    extra_params={
        "top_k": 30,
        "safety_settings": {...}
    }
)
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**é—®é¢˜**: `ValueError: Google API key not found`
**è§£å†³**: ç¡®ä¿è®¾ç½®äº† `GOOGLE_API_KEY` ç¯å¢ƒå˜é‡

**é—®é¢˜**: `Module not found: langchain_google_genai`
**è§£å†³**: è¿è¡Œ `poetry install` å®‰è£…ä¾èµ–

**é—®é¢˜**: `Provider gemini not implemented`
**è§£å†³**: ç¡®ä¿å¯¼å…¥äº† `GeminiProvider` ç±»

**é—®é¢˜**: JSON è§£æé”™è¯¯
**è§£å†³**: Gemini æœ‰æ—¶ç”Ÿæˆéæ ‡å‡† JSONï¼Œå·²å®ç°è‡ªåŠ¨ä¿®å¤

### è°ƒè¯•æŠ€å·§

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**:
```python
import logging
logging.getLogger("app.services.llm_service").setLevel(logging.DEBUG)
```

2. **æŸ¥çœ‹ç”Ÿæˆè¯¦æƒ…**:
```python
result = await provider.generate_structured_script(...)
print(f"Provider: {result['metadata']['provider']}")
print(f"Model: {result['metadata']['model']}")
print(f"Generation time: {result['metadata']['generation_time']}s")
```

3. **å¥åº·æ£€æŸ¥**:
```bash
curl http://localhost:8000/api/v1/game/health
```

## ğŸ“ˆ ç›‘æ§ä¸ä¼˜åŒ–

### æ€§èƒ½ç›‘æ§
- ç”Ÿæˆæ—¶é—´: è®°å½•åœ¨ `metadata.generation_time`
- Token ä½¿ç”¨: è®°å½•åœ¨ `metadata.usage`
- é”™è¯¯ç‡: é€šè¿‡æ—¥å¿—ç›‘æ§

### æˆæœ¬ä¼˜åŒ–
- æ ¹æ®ä»»åŠ¡é€‰æ‹©åˆé€‚çš„æ¨¡å‹
- ä½åç¦»åº¦ä½¿ç”¨ä¾¿å®œæ¨¡å‹
- é«˜åç¦»åº¦ä½¿ç”¨åˆ›æ„æ¨¡å‹

## ğŸš€ æœªæ¥è®¡åˆ’

- [ ] æ·»åŠ  Anthropic Claude æ”¯æŒ
- [ ] å®ç°æ¨¡å‹ A/B æµ‹è¯•
- [ ] æ·»åŠ æœ¬åœ°æ¨¡å‹æ”¯æŒ (Ollama)
- [ ] æ™ºèƒ½æ¨¡å‹é€‰æ‹©ç®—æ³•
- [ ] æˆæœ¬å’Œæ€§èƒ½ç›‘æ§é¢æ¿

---

*æœ¬æŒ‡å—æ¶µç›–äº† WhatIf ç»Ÿä¸€ LLM æä¾›å•†ç³»ç»Ÿçš„å®Œæ•´ä½¿ç”¨æ–¹æ³•ã€‚*