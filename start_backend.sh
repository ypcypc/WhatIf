#!/bin/bash

# WhatIf Backend Service å¯åŠ¨è„šæœ¬
# æ”¯æŒç»Ÿä¸€é…ç½®æ–‡ä»¶ (llm_config.json) å’Œå¤š LLM æä¾›å•†

set -e  # é‡åˆ°é”™è¯¯æ—¶é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ‰“å°å¸¦é¢œè‰²çš„æ¶ˆæ¯
print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•
check_directory() {
    if [[ ! -f "pyproject.toml" ]]; then
        print_error "æœªæ‰¾åˆ° pyproject.toml æ–‡ä»¶ï¼è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬ã€‚"
        exit 1
    fi
    
    if [[ ! -d "backend_services" ]]; then
        print_error "æœªæ‰¾åˆ° backend_services ç›®å½•ï¼è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬ã€‚"
        exit 1
    fi
    
    if [[ ! -f "llm_config.json" ]]; then
        print_error "æœªæ‰¾åˆ°ç»Ÿä¸€é…ç½®æ–‡ä»¶ llm_config.jsonï¼"
        print_info "è¯·åˆ›å»ºé…ç½®æ–‡ä»¶æˆ–ä»æ¨¡æ¿å¤åˆ¶ï¼š"
        print_info "  cp llm_config.json.example llm_config.json"
        exit 1
    fi
    
    print_success "é¡¹ç›®ç›®å½•æ£€æŸ¥é€šè¿‡"
}

# æ£€æŸ¥Poetryæ˜¯å¦å¯ç”¨
check_poetry() {
    if ! command -v poetry &> /dev/null; then
        print_error "Poetry æœªå®‰è£…æˆ–ä¸åœ¨ PATH ä¸­ï¼"
        print_info "è¯·å®‰è£… Poetry æˆ–ç¡®ä¿å®ƒåœ¨æ‚¨çš„ PATH ä¸­ï¼š"
        echo "  curl -sSL https://install.python-poetry.org | python3 -"
        echo "  export PATH=\"\$HOME/.local/bin:\$PATH\""
        exit 1
    fi
    
    print_success "Poetry æ£€æŸ¥é€šè¿‡: $(poetry --version)"
}

# æ£€æŸ¥Pythonç‰ˆæœ¬
check_python() {
    local python_version=$(python3 --version 2>&1 | cut -d' ' -f2)
    print_info "Python ç‰ˆæœ¬: $python_version"
    
    if [[ $(python3 -c "import sys; print(sys.version_info >= (3, 10))") == "False" ]]; then
        print_warning "å»ºè®®ä½¿ç”¨ Python 3.10+ ç‰ˆæœ¬"
    fi
}

# æ£€æŸ¥ç»Ÿä¸€é…ç½®æ–‡ä»¶
check_unified_config() {
    print_info "æ£€æŸ¥ç»Ÿä¸€é…ç½®æ–‡ä»¶..."
    
    if [[ ! -f "llm_config.json" ]]; then
        print_error "ç»Ÿä¸€é…ç½®æ–‡ä»¶ 'llm_config.json' æœªæ‰¾åˆ°ï¼"
        print_info "è¯·åˆ›å»ºé…ç½®æ–‡ä»¶ï¼š"
        print_info "  1. ä»æ¨¡æ¿å¤åˆ¶: cp llm_config.json.example llm_config.json"
        print_info "  2. æˆ–æ‰‹åŠ¨åˆ›å»ºé…ç½®æ–‡ä»¶"
        exit 1
    fi
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦æ˜¯æœ‰æ•ˆçš„JSON
    if ! python3 -c "import json; json.load(open('llm_config.json'))" 2>/dev/null; then
        print_error "llm_config.json ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼"
        print_info "è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶è¯­æ³•"
        exit 1
    fi
    
    # æå–é…ç½®ä¿¡æ¯
    eval $(python3 -c "
import json
config = json.load(open('llm_config.json'))
provider = config.get('llm_provider', {})
api_keys = config.get('api_keys', {})

print(f'DEFAULT_PROVIDER=\"{provider.get(\"default_provider\", \"\")}\"')
print(f'DEFAULT_MODEL=\"{provider.get(\"default_model\", \"\")}\"')
print(f'OPENAI_API_KEY=\"{api_keys.get(\"openai_api_key\", \"\")}\"')
print(f'GOOGLE_API_KEY=\"{api_keys.get(\"google_api_key\", \"\")}\"')
print(f'ANTHROPIC_API_KEY=\"{api_keys.get(\"anthropic_api_key\", \"\")}\"')
")
    
    print_success "é…ç½®æ–‡ä»¶æ ¼å¼æ£€æŸ¥é€šè¿‡"
    print_info "å½“å‰LLMæä¾›å•†: $DEFAULT_PROVIDER"
    print_info "å½“å‰æ¨¡å‹: $DEFAULT_MODEL"
    
    # æ£€æŸ¥å¯¹åº”æä¾›å•†çš„APIå¯†é’¥
    case "$DEFAULT_PROVIDER" in
        "openai")
            if [[ -z "$OPENAI_API_KEY" ]]; then
                print_warning "OpenAI API Key æœªè®¾ç½®ï¼è¯·åœ¨ llm_config.json ä¸­æ·»åŠ  api_keys.openai_api_key"
            else
                print_success "OpenAI API Key å·²é…ç½®"
            fi
            ;;
        "gemini")
            if [[ -z "$GOOGLE_API_KEY" ]]; then
                print_warning "Google API Key æœªè®¾ç½®ï¼è¯·åœ¨ llm_config.json ä¸­æ·»åŠ  api_keys.google_api_key"
            else
                print_success "Google API Key å·²é…ç½®"
            fi
            ;;
        "anthropic")
            if [[ -z "$ANTHROPIC_API_KEY" ]]; then
                print_warning "Anthropic API Key æœªè®¾ç½®ï¼è¯·åœ¨ llm_config.json ä¸­æ·»åŠ  api_keys.anthropic_api_key"
            else
                print_success "Anthropic API Key å·²é…ç½®"
            fi
            ;;
        *)
            print_warning "æœªçŸ¥çš„LLMæä¾›å•†: $DEFAULT_PROVIDER"
            ;;
    esac
}

# æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
check_port() {
    local port=${1:-8000}
    if lsof -Pi :$port -sTCP:LISTEN -t >/dev/null 2>&1; then
        print_warning "ç«¯å£ $port å·²è¢«å ç”¨ï¼æ­£åœ¨å°è¯•ç»ˆæ­¢ç°æœ‰è¿›ç¨‹..."
        # å°è¯•ç»ˆæ­¢å ç”¨ç«¯å£çš„è¿›ç¨‹
        lsof -ti:$port | xargs kill -9 2>/dev/null || true
        sleep 2
        
        # å†æ¬¡æ£€æŸ¥
        if lsof -Pi :$port -sTCP:LISTEN -t >/dev/null 2>&1; then
            print_error "æ— æ³•é‡Šæ”¾ç«¯å£ $portï¼Œè¯·æ‰‹åŠ¨ç»ˆæ­¢ç›¸å…³è¿›ç¨‹"
            exit 1
        fi
    fi
    
    print_success "ç«¯å£ $port å¯ç”¨"
}

# å¯åŠ¨æœåŠ¡
start_service() {
    print_info "å¯åŠ¨ WhatIf Backend Service..."
    print_info "æœåŠ¡å°†åœ¨ http://localhost:8000 å¯åŠ¨"
    print_info "ä½¿ç”¨ LLM æä¾›å•†: $DEFAULT_PROVIDER ($DEFAULT_MODEL)"
    print_info "ç»Ÿä¸€é…ç½®æ–‡ä»¶: llm_config.json"
    print_info "è®°å¿†ç³»ç»Ÿ: ç°ä»£åŒ– LangGraph æ¶æ„"
    print_info "æŒ‰ Ctrl+C åœæ­¢æœåŠ¡"
    echo ""
    
    # å¯åŠ¨æœåŠ¡
    poetry run python start_backend.py
}

# æ¸…ç†å‡½æ•°
cleanup() {
    print_info "æ­£åœ¨æ¸…ç†..."
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ¸…ç†é€»è¾‘
    exit 0
}

# è®¾ç½®ä¿¡å·å¤„ç†
trap cleanup SIGINT SIGTERM

# æ˜¾ç¤ºé…ç½®ä¿¡æ¯
show_config_info() {
    print_info "WhatIf Backend Service é…ç½®ä¿¡æ¯"
    echo "================================"
    
    if [[ ! -f "llm_config.json" ]]; then
        print_error "é…ç½®æ–‡ä»¶ llm_config.json ä¸å­˜åœ¨ï¼"
        return 1
    fi
    
    python3 -c "
import json
from datetime import datetime

try:
    config = json.load(open('llm_config.json'))
    
    print('ğŸ“‹ LLM æä¾›å•†é…ç½®:')
    provider = config.get('llm_provider', {})
    print(f'  é»˜è®¤æä¾›å•†: {provider.get(\"default_provider\", \"æœªè®¾ç½®\")}')
    print(f'  é»˜è®¤æ¨¡å‹: {provider.get(\"default_model\", \"æœªè®¾ç½®\")}')
    
    providers = provider.get('providers', {})
    for prov_name, prov_config in providers.items():
        print(f'  {prov_name.upper()}: {prov_config.get(\"models\", [])}')
    
    print()
    print('ğŸ”‘ API å¯†é’¥çŠ¶æ€:')
    api_keys = config.get('api_keys', {})
    for key_name, key_value in api_keys.items():
        status = 'âœ“ å·²é…ç½®' if key_value else 'âœ— æœªé…ç½®'
        masked_key = key_value[:8] + '...' + key_value[-4:] if key_value and len(key_value) > 12 else 'æœªè®¾ç½®'
        print(f'  {key_name}: {status} ({masked_key})')
    
    print()
    print('âš™ï¸  ç”Ÿæˆè®¾ç½®:')
    gen_settings = config.get('generation_settings', {})
    print(f'  é»˜è®¤æ¸©åº¦: {gen_settings.get(\"default_temperature\", \"æœªè®¾ç½®\")}')
    print(f'  æœ€å¤§Token: {gen_settings.get(\"max_tokens\", \"æœªè®¾ç½®\")}')
    
    memory_settings = gen_settings.get('memory_settings', {})
    print(f'  æœ€å¤§æœ€è¿‘äº‹ä»¶: {memory_settings.get(\"max_recent_events\", \"æœªè®¾ç½®\")}')
    print(f'  å¿«ç…§æœ€å¤§å¤§å°: {memory_settings.get(\"max_snapshot_size\", \"æœªè®¾ç½®\")} bytes')
    
    print()
    print('ğŸ“‚ æ•°æ®è·¯å¾„:')
    data_paths = config.get('data_paths', {})
    for path_name, path_value in data_paths.items():
        print(f'  {path_name}: {path_value}')
    
    print()
    print('ğŸŒ åº”ç”¨è®¾ç½®:')
    app_config = config.get('application', {})
    print(f'  ç«¯å£: {app_config.get(\"port\", \"æœªè®¾ç½®\")}')
    print(f'  è°ƒè¯•æ¨¡å¼: {app_config.get(\"debug\", \"æœªè®¾ç½®\")}')
    
except Exception as e:
    print(f'âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}')
"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    echo "WhatIf Backend Service å¯åŠ¨è„šæœ¬"
    echo ""
    echo "ç”¨æ³•: $0 [é€‰é¡¹]"
    echo ""
    echo "é€‰é¡¹:"
    echo "  -h, --help       æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯"
    echo "  -p, --port       æŒ‡å®šç«¯å£å· (é»˜è®¤: 8000)"
    echo "  --no-check       è·³è¿‡ç¯å¢ƒæ£€æŸ¥"
    echo "  --config-info    æ˜¾ç¤ºå½“å‰é…ç½®ä¿¡æ¯"
    echo ""
    echo "åŠŸèƒ½:"
    echo "  - æ”¯æŒå¤š LLM æä¾›å•† (OpenAI, Gemini, Anthropic)"
    echo "  - ç»Ÿä¸€é…ç½®æ–‡ä»¶ (llm_config.json)"
    echo "  - ç°ä»£åŒ–è®°å¿†ç®¡ç†ç³»ç»Ÿ"
    echo "  - æ™ºèƒ½é”šç‚¹å¤„ç†å’Œä¸‰æ­¥æ³•ç”Ÿæˆ"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0                 # ä½¿ç”¨é»˜è®¤è®¾ç½®å¯åŠ¨"
    echo "  $0 -p 8080         # åœ¨ç«¯å£8080å¯åŠ¨"
    echo "  $0 --no-check      # è·³è¿‡ç¯å¢ƒæ£€æŸ¥ç›´æ¥å¯åŠ¨"
    echo "  $0 --config-info   # æ˜¾ç¤ºé…ç½®ä¿¡æ¯"
}

# ä¸»å‡½æ•°
main() {
    local port=8000
    local skip_check=false
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_help
                exit 0
                ;;
            -p|--port)
                port="$2"
                shift 2
                ;;
            --no-check)
                skip_check=true
                shift
                ;;
            --config-info)
                show_config_info
                exit 0
                ;;
            *)
                print_error "æœªçŸ¥é€‰é¡¹: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    print_info "å¯åŠ¨ WhatIf Backend Service..."
    echo "================================"
    
    if [[ "$skip_check" == false ]]; then
        # æ‰§è¡Œæ£€æŸ¥
        check_directory
        check_poetry
        check_python
        check_unified_config
        check_port $port
    fi
    
    echo "================================"
    print_success "ç¯å¢ƒæ£€æŸ¥å®Œæˆï¼Œå‡†å¤‡å¯åŠ¨æœåŠ¡..."
    echo ""
    
    # å¯åŠ¨æœåŠ¡
    start_service
}

# å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œåˆ™æ‰§è¡Œä¸»å‡½æ•°
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
